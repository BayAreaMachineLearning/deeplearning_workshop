{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classifying with artificial neurons\n",
    "\n",
    "## Introduction: The perceptron\n",
    "\n",
    "The first example of this notebook is a binary classifier by means of the Logistic Regression operation. This model is also called Perceptron or Artificial Neuron, depicted in the figure below.\n",
    "\n",
    "![perceptron](assets/perceptron.png)\n",
    "\n",
    "There we have a set of inputs {x1, x2, x3}, a set of weights {w1, w2, w3}, a bias factor {b} and an activation function {f}, and the following operations are applied:\n",
    "\n",
    "$$y = f(\\sum_{m=1}^{M} x_i * w_i + b)$$\n",
    "\n",
    "To actually make it a binary classifier we must place a specific type of activation function called Sigmoid: \n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{(1 + {e}^{-z})}$$ where $$z = x * w + b$$\n",
    "\n",
    "The Sigmoid shape is depicted in the figure below:\n",
    "\n",
    "![sigmoid](assets/sigmoid.png)\n",
    "\n",
    "We can see how, depending on the weights and biases (in the depicted figure all sigmoids have scalar values, so only one input x1 would be injected) there is a ridge bounding the outputs between (0, 1), which can be interpreted as a probability output depending on the inputs that activate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exercise 1: It is a number or is it noise?\n",
    "\n",
    "In this example we will classify whether an image is noise or a MNIST digit:\n",
    "* MNIST dataset contains images of 10 handwritten digit classes {0, 1, 2, 3, 4, ..., 9}. Each class contains 6.000 images of 28x28 pixels.\n",
    "\n",
    "We will use 50.000 images for training and 10.000 for testing our classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import print utility and timer\n",
    "from __future__ import print_function\n",
    "import timeit\n",
    "# First import tensorflow and the data reader\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "# numpy for matrix utilities\n",
    "import numpy as np\n",
    "from utils import plot_samples\n",
    "# import plot utilities\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Computed unrolled size:  784\n"
     ]
    }
   ],
   "source": [
    "# define IMG dimensions\n",
    "IMG_SIZE=28\n",
    "# Import mnist data\n",
    "mnist = input_data.read_data_sets('data/mnist/', one_hot=True)\n",
    "# Make the random images generator (28x28 withdrawn from a random uniform distribution)\n",
    "def make_random_batch(batch_size):\n",
    "    # Generate batch_size images of size image_size x image_size\n",
    "    rimg = np.random.uniform(low=0., high=1., size=(batch_size, IMG_SIZE * IMG_SIZE))\n",
    "    return rimg\n",
    "# Define num of pixels that will be input to models\n",
    "unrolled_size = IMG_SIZE * IMG_SIZE\n",
    "print(\"Computed unrolled size: \", unrolled_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD8CAYAAABJsn7AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIJBiAEWBEEwiP8HQGc0bIFmyBgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117f94358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize some MNIST samples\n",
    "batch_x_real, _ = mnist.train.next_batch(100)\n",
    "batch_x_real = batch_x_real.reshape((100, 28, 28))\n",
    "plot_samples(batch_x_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise:** Define the model operation of logistic regression equation and the placeholder to insert groundtruth binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W is  Tensor(\"Variable_2/read:0\", shape=(784, 1), dtype=float32)\n",
      "x is Tensor(\"Placeholder_2:0\", shape=(?, 784), dtype=float32)\n",
      "y is Tensor(\"add_1:0\", shape=(?, 1), dtype=float32)\n",
      "out is Tensor(\"Sigmoid_1:0\", shape=(?, 1), dtype=float32)\n",
      "y_ is Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the model, recall logistic regression equation\n",
    "# Define weights matrix (from unrolled_size inputs to 1 classification output (noise(0)/mnist(1)))\n",
    "W = tf.Variable(tf.zeros([unrolled_size, 1]))\n",
    "\n",
    "print(\"W is \",W)\n",
    "\n",
    "# the bias is summing just a scalar output, so dimension 1\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "# define an input placeholder to inject the vectorized images\n",
    "# None indicates we don't know batch_size yet, will be specified when running the training\n",
    "x = tf.placeholder(tf.float32, [None, unrolled_size]) \n",
    "\n",
    "print(\"x is\",x)\n",
    "\n",
    "# TODO: Logistic Regression equation implementation\n",
    "y = tf.matmul(x, W) + b\n",
    "\n",
    "print(\"y is\",y)\n",
    "\n",
    "# apply sigmoid to get final predictions\n",
    "out = tf.sigmoid(y)\n",
    "\n",
    "print(\"out is\", out)\n",
    "\n",
    "# TODO: Now we define the placeholder to place the flag (0 or 1) as output examples\n",
    "y_ = tf.placeholder(tf.float32,[None,1])\n",
    "print(\"y_ is\",y_)\n",
    "\n",
    "# Now call the sigmoid cross entropy with logits to compute the loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "\n",
    "# define the gradients update operation with learning rate of 0.05\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Batch 10000/50000 training loss: 0.000160\n",
      "Batch 20000/50000 training loss: 0.000308\n",
      "Batch 30000/50000 training loss: 0.000071\n",
      "Batch 40000/50000 training loss: 0.000053\n",
      "Batch 50000/50000 training loss: 0.000040\n",
      "Total time training 1 epochs: 51.6676324630389 s\n"
     ]
    }
   ],
   "source": [
    "# initialize the TensorFlow session to run the operations Graph \"on the fly\" (not usual in production code)\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# specify number of epochs to run through whole dataset\n",
    "num_epochs = 1 # approx 55 s / epoch on laptop (macbook pro 13\" i7 end 2011 w/ 8GB RAM) w/ batch_size = 10\n",
    "# compute total amount of batches to be run\n",
    "train_size = 50000\n",
    "num_batches = int(train_size * num_epochs)\n",
    "# specify batch_size \n",
    "batch_size = 10\n",
    "# print loss after this amount of batches\n",
    "print_every = 10000\n",
    "tr_losses = []\n",
    "\n",
    "print('Training...')\n",
    "beg_t = timeit.default_timer()\n",
    "# Run the training iterations\n",
    "for curr_batch in range(num_batches):\n",
    "    # get the batch of training images (to be injected to x placeholder)\n",
    "    batch_x_real, _ = mnist.train.next_batch(batch_size)\n",
    "    # create the batch of labels (to be injected to y_ placeholder)\n",
    "    batch_y_real = np.ones((batch_size, 1))\n",
    "    # generate the batch of random images (to be injected to x placeholder)\n",
    "    batch_x_random = make_random_batch(batch_size)\n",
    "    # create the batch of 0 labels (to be injectd to y_ placeholder)\n",
    "    batch_y_random = np.zeros((batch_size, 1))\n",
    "    # merge both batches into one and run update\n",
    "    batch_x = np.concatenate((batch_x_real, batch_x_random), axis=0)\n",
    "    batch_y = np.concatenate((batch_y_real, batch_y_random), axis=0)\n",
    "    # run model update (learning stage over a batch of samples)\n",
    "    tr_loss , _= sess.run([loss, train_step], feed_dict={x: batch_x, y_:batch_y})\n",
    "    tr_losses.append(tr_loss)\n",
    "    if (curr_batch + 1) % print_every == 0:\n",
    "        print('Batch {}/{} training loss: {:.6f}'.format(curr_batch + 1, num_batches, tr_loss))\n",
    "end_t = timeit.default_timer()\n",
    "print('Total time training {} epochs: {} s'.format(num_epochs, end_t - beg_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x124bd51d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAEKCAYAAADzbDcqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124eff518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.semilogy(tr_losses)\n",
    "plt.xlabel('Batch index')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise:** Call the right test op to evaluate the performance of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test trained model\n",
    "# generate the random test images\n",
    "te_x_random = make_random_batch(10000)\n",
    "te_y_random = np.zeros((10000, 1))\n",
    "# cache the real test images\n",
    "te_x_real = mnist.test.images\n",
    "te_y_real = np.ones((10000, 1))\n",
    "# total test batches\n",
    "te_x_batch = np.concatenate((te_x_random, te_x_real), axis=0)\n",
    "te_y_batch = np.concatenate((te_y_random, te_y_real), axis=0)\n",
    "# define the accuracy computation op\n",
    "# NOTE: the sigmoid output is rounded so that if out >= 0.5 --> predicts 1, otherwise predicts 0\n",
    "correct_prediction = tf.equal(tf.round(out), y_)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# TODO: print Accuracy computation running the accuracy op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exercise 2: What number is it? Scaling up to multiple classes\n",
    "Now that a binary classification task has been solved we will see its natural extension: a multiclass classifier.\n",
    "This can be done by means of a softmax layer. The softmax layer is a parallel arrangement of sigmoidal neurons (*Output Layer* in the image below), where every neuron indicates the amount of probability that the input features (*Input Layer* in the image below) belong to a certain class.\n",
    "\n",
    "![softmax](assets/softmax_img.png)\n",
    "\n",
    "\n",
    "As it is a probability distribution between the possible classes, all of them must sum up to 1. So the softmax formulation is the following one:\n",
    "\n",
    "$$y = \\frac{e^{x^T * w_k}}{\\sum_{n=1}^{N} e^{x^T * w_n}}$$\n",
    "\n",
    "where x and w are vectors representing inputs $x$ and k-th layer weights $w_k$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reset graph here\n",
    "tf.reset_default_graph()\n",
    "# initialize the TensorFlow session to run the operations Graph \"on the fly\" (not usual in production code)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First, define the new weights and biases to express the multiple output neurons\n",
    "# TODO: Define weights matrix (from unrolled_size inputs to 10 classification outputs (10 MNIST digits)\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "# TODO: define the biases\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "# TODO: define an input placeholder to inject the vectorized images\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "# TODO: equation implementation\n",
    "y = tf.matmul(x, W) + b\n",
    "# apply sigmoid to get final predictions\n",
    "out = tf.nn.softmax(y)\n",
    "\n",
    "# TODO: Now we define the placeholder to place the classes\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# TODO: Now call the softmax cross entropy with logits to compute the loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "\n",
    "# TODO: define the gradients update operation with learning rate of 0.05\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Batch 10/10000 training loss: 1.879650\n",
      "Batch 20/10000 training loss: 1.662354\n",
      "Batch 30/10000 training loss: 1.374051\n",
      "Batch 40/10000 training loss: 1.157296\n",
      "Batch 50/10000 training loss: 1.114071\n",
      "Batch 60/10000 training loss: 1.049136\n",
      "Batch 70/10000 training loss: 0.861201\n",
      "Batch 80/10000 training loss: 0.876145\n",
      "Batch 90/10000 training loss: 0.929143\n",
      "Batch 100/10000 training loss: 0.955375\n",
      "Batch 110/10000 training loss: 0.744504\n",
      "Batch 120/10000 training loss: 0.704396\n",
      "Batch 130/10000 training loss: 0.780176\n",
      "Batch 140/10000 training loss: 0.655717\n",
      "Batch 150/10000 training loss: 0.601860\n",
      "Batch 160/10000 training loss: 0.557990\n",
      "Batch 170/10000 training loss: 0.713274\n",
      "Batch 180/10000 training loss: 0.558582\n",
      "Batch 190/10000 training loss: 0.612894\n",
      "Batch 200/10000 training loss: 0.662879\n",
      "Batch 210/10000 training loss: 0.731014\n",
      "Batch 220/10000 training loss: 0.485878\n",
      "Batch 230/10000 training loss: 0.498293\n",
      "Batch 240/10000 training loss: 0.488691\n",
      "Batch 250/10000 training loss: 0.566252\n",
      "Batch 260/10000 training loss: 0.553048\n",
      "Batch 270/10000 training loss: 0.599802\n",
      "Batch 280/10000 training loss: 0.492283\n",
      "Batch 290/10000 training loss: 0.611462\n",
      "Batch 300/10000 training loss: 0.685957\n",
      "Batch 310/10000 training loss: 0.563303\n",
      "Batch 320/10000 training loss: 0.534769\n",
      "Batch 330/10000 training loss: 0.583962\n",
      "Batch 340/10000 training loss: 0.654308\n",
      "Batch 350/10000 training loss: 0.551250\n",
      "Batch 360/10000 training loss: 0.636399\n",
      "Batch 370/10000 training loss: 0.505110\n",
      "Batch 380/10000 training loss: 0.534341\n",
      "Batch 390/10000 training loss: 0.546633\n",
      "Batch 400/10000 training loss: 0.460746\n",
      "Batch 410/10000 training loss: 0.548741\n",
      "Batch 420/10000 training loss: 0.410823\n",
      "Batch 430/10000 training loss: 0.506720\n",
      "Batch 440/10000 training loss: 0.368316\n",
      "Batch 450/10000 training loss: 0.617720\n",
      "Batch 460/10000 training loss: 0.399230\n",
      "Batch 470/10000 training loss: 0.427353\n",
      "Batch 480/10000 training loss: 0.418104\n",
      "Batch 490/10000 training loss: 0.542770\n",
      "Batch 500/10000 training loss: 0.411040\n",
      "Batch 510/10000 training loss: 0.470913\n",
      "Batch 520/10000 training loss: 0.509223\n",
      "Batch 530/10000 training loss: 0.577550\n",
      "Batch 540/10000 training loss: 0.508834\n",
      "Batch 550/10000 training loss: 0.458950\n",
      "Batch 560/10000 training loss: 0.495888\n",
      "Batch 570/10000 training loss: 0.503045\n",
      "Batch 580/10000 training loss: 0.490578\n",
      "Batch 590/10000 training loss: 0.384403\n",
      "Batch 600/10000 training loss: 0.473395\n",
      "Batch 610/10000 training loss: 0.370028\n",
      "Batch 620/10000 training loss: 0.557658\n",
      "Batch 630/10000 training loss: 0.432736\n",
      "Batch 640/10000 training loss: 0.565912\n",
      "Batch 650/10000 training loss: 0.368652\n",
      "Batch 660/10000 training loss: 0.407532\n",
      "Batch 670/10000 training loss: 0.311427\n",
      "Batch 680/10000 training loss: 0.306523\n",
      "Batch 690/10000 training loss: 0.352163\n",
      "Batch 700/10000 training loss: 0.357481\n",
      "Batch 710/10000 training loss: 0.345016\n",
      "Batch 720/10000 training loss: 0.457767\n",
      "Batch 730/10000 training loss: 0.472567\n",
      "Batch 740/10000 training loss: 0.392359\n",
      "Batch 750/10000 training loss: 0.334447\n",
      "Batch 760/10000 training loss: 0.483929\n",
      "Batch 770/10000 training loss: 0.526938\n",
      "Batch 780/10000 training loss: 0.417130\n",
      "Batch 790/10000 training loss: 0.445089\n",
      "Batch 800/10000 training loss: 0.386929\n",
      "Batch 810/10000 training loss: 0.436306\n",
      "Batch 820/10000 training loss: 0.460401\n",
      "Batch 830/10000 training loss: 0.480072\n",
      "Batch 840/10000 training loss: 0.369556\n",
      "Batch 850/10000 training loss: 0.449972\n",
      "Batch 860/10000 training loss: 0.351685\n",
      "Batch 870/10000 training loss: 0.281541\n",
      "Batch 880/10000 training loss: 0.534199\n",
      "Batch 890/10000 training loss: 0.379780\n",
      "Batch 900/10000 training loss: 0.401513\n",
      "Batch 910/10000 training loss: 0.394865\n",
      "Batch 920/10000 training loss: 0.404980\n",
      "Batch 930/10000 training loss: 0.338511\n",
      "Batch 940/10000 training loss: 0.373362\n",
      "Batch 950/10000 training loss: 0.433361\n",
      "Batch 960/10000 training loss: 0.482282\n",
      "Batch 970/10000 training loss: 0.468104\n",
      "Batch 980/10000 training loss: 0.334061\n",
      "Batch 990/10000 training loss: 0.297567\n",
      "Batch 1000/10000 training loss: 0.313364\n",
      "Batch 1010/10000 training loss: 0.337880\n",
      "Batch 1020/10000 training loss: 0.379367\n",
      "Batch 1030/10000 training loss: 0.304384\n",
      "Batch 1040/10000 training loss: 0.528633\n",
      "Batch 1050/10000 training loss: 0.419840\n",
      "Batch 1060/10000 training loss: 0.407417\n",
      "Batch 1070/10000 training loss: 0.416273\n",
      "Batch 1080/10000 training loss: 0.377866\n",
      "Batch 1090/10000 training loss: 0.252054\n",
      "Batch 1100/10000 training loss: 0.558963\n",
      "Batch 1110/10000 training loss: 0.314026\n",
      "Batch 1120/10000 training loss: 0.294978\n",
      "Batch 1130/10000 training loss: 0.322757\n",
      "Batch 1140/10000 training loss: 0.448025\n",
      "Batch 1150/10000 training loss: 0.310216\n",
      "Batch 1160/10000 training loss: 0.412146\n",
      "Batch 1170/10000 training loss: 0.378149\n",
      "Batch 1180/10000 training loss: 0.323855\n",
      "Batch 1190/10000 training loss: 0.541364\n",
      "Batch 1200/10000 training loss: 0.270046\n",
      "Batch 1210/10000 training loss: 0.430599\n",
      "Batch 1220/10000 training loss: 0.359692\n",
      "Batch 1230/10000 training loss: 0.420496\n",
      "Batch 1240/10000 training loss: 0.236257\n",
      "Batch 1250/10000 training loss: 0.405176\n",
      "Batch 1260/10000 training loss: 0.502179\n",
      "Batch 1270/10000 training loss: 0.383707\n",
      "Batch 1280/10000 training loss: 0.372012\n",
      "Batch 1290/10000 training loss: 0.432226\n",
      "Batch 1300/10000 training loss: 0.372430\n",
      "Batch 1310/10000 training loss: 0.342229\n",
      "Batch 1320/10000 training loss: 0.351869\n",
      "Batch 1330/10000 training loss: 0.380225\n",
      "Batch 1340/10000 training loss: 0.283869\n",
      "Batch 1350/10000 training loss: 0.538165\n",
      "Batch 1360/10000 training loss: 0.410032\n",
      "Batch 1370/10000 training loss: 0.544948\n",
      "Batch 1380/10000 training loss: 0.548363\n",
      "Batch 1390/10000 training loss: 0.438467\n",
      "Batch 1400/10000 training loss: 0.414128\n",
      "Batch 1410/10000 training loss: 0.418399\n",
      "Batch 1420/10000 training loss: 0.327264\n",
      "Batch 1430/10000 training loss: 0.377945\n",
      "Batch 1440/10000 training loss: 0.186369\n",
      "Batch 1450/10000 training loss: 0.424888\n",
      "Batch 1460/10000 training loss: 0.470642\n",
      "Batch 1470/10000 training loss: 0.305547\n",
      "Batch 1480/10000 training loss: 0.336176\n",
      "Batch 1490/10000 training loss: 0.290857\n",
      "Batch 1500/10000 training loss: 0.385318\n",
      "Batch 1510/10000 training loss: 0.296865\n",
      "Batch 1520/10000 training loss: 0.330181\n",
      "Batch 1530/10000 training loss: 0.359223\n",
      "Batch 1540/10000 training loss: 0.354514\n",
      "Batch 1550/10000 training loss: 0.310553\n",
      "Batch 1560/10000 training loss: 0.339487\n",
      "Batch 1570/10000 training loss: 0.384078\n",
      "Batch 1580/10000 training loss: 0.462706\n",
      "Batch 1590/10000 training loss: 0.452993\n",
      "Batch 1600/10000 training loss: 0.341282\n",
      "Batch 1610/10000 training loss: 0.371291\n",
      "Batch 1620/10000 training loss: 0.309035\n",
      "Batch 1630/10000 training loss: 0.408057\n",
      "Batch 1640/10000 training loss: 0.506213\n",
      "Batch 1650/10000 training loss: 0.209900\n",
      "Batch 1660/10000 training loss: 0.380727\n",
      "Batch 1670/10000 training loss: 0.320982\n",
      "Batch 1680/10000 training loss: 0.325552\n",
      "Batch 1690/10000 training loss: 0.339751\n",
      "Batch 1700/10000 training loss: 0.448171\n",
      "Batch 1710/10000 training loss: 0.306289\n",
      "Batch 1720/10000 training loss: 0.426042\n",
      "Batch 1730/10000 training loss: 0.306165\n",
      "Batch 1740/10000 training loss: 0.392248\n",
      "Batch 1750/10000 training loss: 0.308650\n",
      "Batch 1760/10000 training loss: 0.409460\n",
      "Batch 1770/10000 training loss: 0.261715\n",
      "Batch 1780/10000 training loss: 0.344176\n",
      "Batch 1790/10000 training loss: 0.300814\n",
      "Batch 1800/10000 training loss: 0.346352\n",
      "Batch 1810/10000 training loss: 0.230614\n",
      "Batch 1820/10000 training loss: 0.212057\n",
      "Batch 1830/10000 training loss: 0.433235\n",
      "Batch 1840/10000 training loss: 0.359164\n",
      "Batch 1850/10000 training loss: 0.408584\n",
      "Batch 1860/10000 training loss: 0.455588\n",
      "Batch 1870/10000 training loss: 0.355045\n",
      "Batch 1880/10000 training loss: 0.307804\n",
      "Batch 1890/10000 training loss: 0.338307\n",
      "Batch 1900/10000 training loss: 0.230719\n",
      "Batch 1910/10000 training loss: 0.479501\n",
      "Batch 1920/10000 training loss: 0.195742\n",
      "Batch 1930/10000 training loss: 0.403552\n",
      "Batch 1940/10000 training loss: 0.640286\n",
      "Batch 1950/10000 training loss: 0.427665\n",
      "Batch 1960/10000 training loss: 0.286653\n",
      "Batch 1970/10000 training loss: 0.219051\n",
      "Batch 1980/10000 training loss: 0.366826\n",
      "Batch 1990/10000 training loss: 0.234813\n",
      "Batch 2000/10000 training loss: 0.319925\n",
      "Batch 2010/10000 training loss: 0.508007\n",
      "Batch 2020/10000 training loss: 0.424305\n",
      "Batch 2030/10000 training loss: 0.613348\n",
      "Batch 2040/10000 training loss: 0.381998\n",
      "Batch 2050/10000 training loss: 0.233439\n",
      "Batch 2060/10000 training loss: 0.272747\n",
      "Batch 2070/10000 training loss: 0.527316\n",
      "Batch 2080/10000 training loss: 0.314111\n",
      "Batch 2090/10000 training loss: 0.228727\n",
      "Batch 2100/10000 training loss: 0.427067\n",
      "Batch 2110/10000 training loss: 0.294212\n",
      "Batch 2120/10000 training loss: 0.282942\n",
      "Batch 2130/10000 training loss: 0.326806\n",
      "Batch 2140/10000 training loss: 0.343608\n",
      "Batch 2150/10000 training loss: 0.319782\n",
      "Batch 2160/10000 training loss: 0.513395\n",
      "Batch 2170/10000 training loss: 0.276914\n",
      "Batch 2180/10000 training loss: 0.462058\n",
      "Batch 2190/10000 training loss: 0.167587\n",
      "Batch 2200/10000 training loss: 0.423573\n",
      "Batch 2210/10000 training loss: 0.298411\n",
      "Batch 2220/10000 training loss: 0.318669\n",
      "Batch 2230/10000 training loss: 0.268002\n",
      "Batch 2240/10000 training loss: 0.334481\n",
      "Batch 2250/10000 training loss: 0.329587\n",
      "Batch 2260/10000 training loss: 0.423519\n",
      "Batch 2270/10000 training loss: 0.308607\n",
      "Batch 2280/10000 training loss: 0.464494\n",
      "Batch 2290/10000 training loss: 0.262508\n",
      "Batch 2300/10000 training loss: 0.357874\n",
      "Batch 2310/10000 training loss: 0.264629\n",
      "Batch 2320/10000 training loss: 0.326586\n",
      "Batch 2330/10000 training loss: 0.333572\n",
      "Batch 2340/10000 training loss: 0.381825\n",
      "Batch 2350/10000 training loss: 0.300165\n",
      "Batch 2360/10000 training loss: 0.341829\n",
      "Batch 2370/10000 training loss: 0.439946\n",
      "Batch 2380/10000 training loss: 0.364261\n",
      "Batch 2390/10000 training loss: 0.318471\n",
      "Batch 2400/10000 training loss: 0.509387\n",
      "Batch 2410/10000 training loss: 0.448077\n",
      "Batch 2420/10000 training loss: 0.306547\n",
      "Batch 2430/10000 training loss: 0.357275\n",
      "Batch 2440/10000 training loss: 0.320682\n",
      "Batch 2450/10000 training loss: 0.359968\n",
      "Batch 2460/10000 training loss: 0.316320\n",
      "Batch 2470/10000 training loss: 0.239103\n",
      "Batch 2480/10000 training loss: 0.307018\n",
      "Batch 2490/10000 training loss: 0.318703\n",
      "Batch 2500/10000 training loss: 0.424300\n",
      "Batch 2510/10000 training loss: 0.270791\n",
      "Batch 2520/10000 training loss: 0.472269\n",
      "Batch 2530/10000 training loss: 0.288493\n",
      "Batch 2540/10000 training loss: 0.411382\n",
      "Batch 2550/10000 training loss: 0.367996\n",
      "Batch 2560/10000 training loss: 0.439223\n",
      "Batch 2570/10000 training loss: 0.278497\n",
      "Batch 2580/10000 training loss: 0.302222\n",
      "Batch 2590/10000 training loss: 0.439279\n",
      "Batch 2600/10000 training loss: 0.323195\n",
      "Batch 2610/10000 training loss: 0.265090\n",
      "Batch 2620/10000 training loss: 0.276084\n",
      "Batch 2630/10000 training loss: 0.300604\n",
      "Batch 2640/10000 training loss: 0.492749\n",
      "Batch 2650/10000 training loss: 0.253254\n",
      "Batch 2660/10000 training loss: 0.411279\n",
      "Batch 2670/10000 training loss: 0.337685\n",
      "Batch 2680/10000 training loss: 0.588665\n",
      "Batch 2690/10000 training loss: 0.301943\n",
      "Batch 2700/10000 training loss: 0.383905\n",
      "Batch 2710/10000 training loss: 0.383369\n",
      "Batch 2720/10000 training loss: 0.311925\n",
      "Batch 2730/10000 training loss: 0.184741\n",
      "Batch 2740/10000 training loss: 0.331061\n",
      "Batch 2750/10000 training loss: 0.286444\n",
      "Batch 2760/10000 training loss: 0.416637\n",
      "Batch 2770/10000 training loss: 0.448973\n",
      "Batch 2780/10000 training loss: 0.298107\n",
      "Batch 2790/10000 training loss: 0.279082\n",
      "Batch 2800/10000 training loss: 0.432975\n",
      "Batch 2810/10000 training loss: 0.219137\n",
      "Batch 2820/10000 training loss: 0.381018\n",
      "Batch 2830/10000 training loss: 0.326378\n",
      "Batch 2840/10000 training loss: 0.309453\n",
      "Batch 2850/10000 training loss: 0.212983\n",
      "Batch 2860/10000 training loss: 0.417162\n",
      "Batch 2870/10000 training loss: 0.285154\n",
      "Batch 2880/10000 training loss: 0.292831\n",
      "Batch 2890/10000 training loss: 0.405118\n",
      "Batch 2900/10000 training loss: 0.380019\n",
      "Batch 2910/10000 training loss: 0.380850\n",
      "Batch 2920/10000 training loss: 0.382929\n",
      "Batch 2930/10000 training loss: 0.361324\n",
      "Batch 2940/10000 training loss: 0.337369\n",
      "Batch 2950/10000 training loss: 0.427680\n",
      "Batch 2960/10000 training loss: 0.293923\n",
      "Batch 2970/10000 training loss: 0.271223\n",
      "Batch 2980/10000 training loss: 0.280762\n",
      "Batch 2990/10000 training loss: 0.287545\n",
      "Batch 3000/10000 training loss: 0.371408\n",
      "Batch 3010/10000 training loss: 0.268612\n",
      "Batch 3020/10000 training loss: 0.249868\n",
      "Batch 3030/10000 training loss: 0.390652\n",
      "Batch 3040/10000 training loss: 0.250997\n",
      "Batch 3050/10000 training loss: 0.355051\n",
      "Batch 3060/10000 training loss: 0.255770\n",
      "Batch 3070/10000 training loss: 0.363748\n",
      "Batch 3080/10000 training loss: 0.514731\n",
      "Batch 3090/10000 training loss: 0.457415\n",
      "Batch 3100/10000 training loss: 0.266607\n",
      "Batch 3110/10000 training loss: 0.245392\n",
      "Batch 3120/10000 training loss: 0.456160\n",
      "Batch 3130/10000 training loss: 0.542011\n",
      "Batch 3140/10000 training loss: 0.304276\n",
      "Batch 3150/10000 training loss: 0.378539\n",
      "Batch 3160/10000 training loss: 0.267269\n",
      "Batch 3170/10000 training loss: 0.363217\n",
      "Batch 3180/10000 training loss: 0.204765\n",
      "Batch 3190/10000 training loss: 0.348494\n",
      "Batch 3200/10000 training loss: 0.249650\n",
      "Batch 3210/10000 training loss: 0.484108\n",
      "Batch 3220/10000 training loss: 0.302222\n",
      "Batch 3230/10000 training loss: 0.315428\n",
      "Batch 3240/10000 training loss: 0.340974\n",
      "Batch 3250/10000 training loss: 0.375944\n",
      "Batch 3260/10000 training loss: 0.422848\n",
      "Batch 3270/10000 training loss: 0.329780\n",
      "Batch 3280/10000 training loss: 0.244655\n",
      "Batch 3290/10000 training loss: 0.335253\n",
      "Batch 3300/10000 training loss: 0.278896\n",
      "Batch 3310/10000 training loss: 0.291335\n",
      "Batch 3320/10000 training loss: 0.181427\n",
      "Batch 3330/10000 training loss: 0.490545\n",
      "Batch 3340/10000 training loss: 0.244676\n",
      "Batch 3350/10000 training loss: 0.248016\n",
      "Batch 3360/10000 training loss: 0.347658\n",
      "Batch 3370/10000 training loss: 0.369031\n",
      "Batch 3380/10000 training loss: 0.359071\n",
      "Batch 3390/10000 training loss: 0.393148\n",
      "Batch 3400/10000 training loss: 0.258722\n",
      "Batch 3410/10000 training loss: 0.398404\n",
      "Batch 3420/10000 training loss: 0.365816\n",
      "Batch 3430/10000 training loss: 0.435572\n",
      "Batch 3440/10000 training loss: 0.355586\n",
      "Batch 3450/10000 training loss: 0.321554\n",
      "Batch 3460/10000 training loss: 0.413554\n",
      "Batch 3470/10000 training loss: 0.255643\n",
      "Batch 3480/10000 training loss: 0.355646\n",
      "Batch 3490/10000 training loss: 0.399938\n",
      "Batch 3500/10000 training loss: 0.295066\n",
      "Batch 3510/10000 training loss: 0.297562\n",
      "Batch 3520/10000 training loss: 0.201284\n",
      "Batch 3530/10000 training loss: 0.322801\n",
      "Batch 3540/10000 training loss: 0.353861\n",
      "Batch 3550/10000 training loss: 0.326935\n",
      "Batch 3560/10000 training loss: 0.340764\n",
      "Batch 3570/10000 training loss: 0.453315\n",
      "Batch 3580/10000 training loss: 0.305984\n",
      "Batch 3590/10000 training loss: 0.384746\n",
      "Batch 3600/10000 training loss: 0.200306\n",
      "Batch 3610/10000 training loss: 0.230266\n",
      "Batch 3620/10000 training loss: 0.311780\n",
      "Batch 3630/10000 training loss: 0.209962\n",
      "Batch 3640/10000 training loss: 0.222552\n",
      "Batch 3650/10000 training loss: 0.221137\n",
      "Batch 3660/10000 training loss: 0.494952\n",
      "Batch 3670/10000 training loss: 0.437033\n",
      "Batch 3680/10000 training loss: 0.283982\n",
      "Batch 3690/10000 training loss: 0.220764\n",
      "Batch 3700/10000 training loss: 0.294246\n",
      "Batch 3710/10000 training loss: 0.411750\n",
      "Batch 3720/10000 training loss: 0.256601\n",
      "Batch 3730/10000 training loss: 0.263128\n",
      "Batch 3740/10000 training loss: 0.315565\n",
      "Batch 3750/10000 training loss: 0.217898\n",
      "Batch 3760/10000 training loss: 0.245412\n",
      "Batch 3770/10000 training loss: 0.291171\n",
      "Batch 3780/10000 training loss: 0.351351\n",
      "Batch 3790/10000 training loss: 0.388652\n",
      "Batch 3800/10000 training loss: 0.319180\n",
      "Batch 3810/10000 training loss: 0.321668\n",
      "Batch 3820/10000 training loss: 0.268944\n",
      "Batch 3830/10000 training loss: 0.237167\n",
      "Batch 3840/10000 training loss: 0.400262\n",
      "Batch 3850/10000 training loss: 0.316887\n",
      "Batch 3860/10000 training loss: 0.242685\n",
      "Batch 3870/10000 training loss: 0.264603\n",
      "Batch 3880/10000 training loss: 0.201179\n",
      "Batch 3890/10000 training loss: 0.242662\n",
      "Batch 3900/10000 training loss: 0.244957\n",
      "Batch 3910/10000 training loss: 0.435861\n",
      "Batch 3920/10000 training loss: 0.384451\n",
      "Batch 3930/10000 training loss: 0.441031\n",
      "Batch 3940/10000 training loss: 0.430475\n",
      "Batch 3950/10000 training loss: 0.480228\n",
      "Batch 3960/10000 training loss: 0.310814\n",
      "Batch 3970/10000 training loss: 0.343316\n",
      "Batch 3980/10000 training loss: 0.354464\n",
      "Batch 3990/10000 training loss: 0.298743\n",
      "Batch 4000/10000 training loss: 0.235067\n",
      "Batch 4010/10000 training loss: 0.352725\n",
      "Batch 4020/10000 training loss: 0.331552\n",
      "Batch 4030/10000 training loss: 0.280791\n",
      "Batch 4040/10000 training loss: 0.376021\n",
      "Batch 4050/10000 training loss: 0.356130\n",
      "Batch 4060/10000 training loss: 0.328029\n",
      "Batch 4070/10000 training loss: 0.386659\n",
      "Batch 4080/10000 training loss: 0.220107\n",
      "Batch 4090/10000 training loss: 0.238302\n",
      "Batch 4100/10000 training loss: 0.395211\n",
      "Batch 4110/10000 training loss: 0.254276\n",
      "Batch 4120/10000 training loss: 0.266858\n",
      "Batch 4130/10000 training loss: 0.323787\n",
      "Batch 4140/10000 training loss: 0.226735\n",
      "Batch 4150/10000 training loss: 0.301715\n",
      "Batch 4160/10000 training loss: 0.225752\n",
      "Batch 4170/10000 training loss: 0.486565\n",
      "Batch 4180/10000 training loss: 0.539047\n",
      "Batch 4190/10000 training loss: 0.210557\n",
      "Batch 4200/10000 training loss: 0.251154\n",
      "Batch 4210/10000 training loss: 0.439340\n",
      "Batch 4220/10000 training loss: 0.322876\n",
      "Batch 4230/10000 training loss: 0.260598\n",
      "Batch 4240/10000 training loss: 0.375414\n",
      "Batch 4250/10000 training loss: 0.486404\n",
      "Batch 4260/10000 training loss: 0.328432\n",
      "Batch 4270/10000 training loss: 0.361784\n",
      "Batch 4280/10000 training loss: 0.342816\n",
      "Batch 4290/10000 training loss: 0.181824\n",
      "Batch 4300/10000 training loss: 0.388793\n",
      "Batch 4310/10000 training loss: 0.293345\n",
      "Batch 4320/10000 training loss: 0.145774\n",
      "Batch 4330/10000 training loss: 0.328598\n",
      "Batch 4340/10000 training loss: 0.179350\n",
      "Batch 4350/10000 training loss: 0.388383\n",
      "Batch 4360/10000 training loss: 0.260529\n",
      "Batch 4370/10000 training loss: 0.272493\n",
      "Batch 4380/10000 training loss: 0.314209\n",
      "Batch 4390/10000 training loss: 0.307347\n",
      "Batch 4400/10000 training loss: 0.217085\n",
      "Batch 4410/10000 training loss: 0.295828\n",
      "Batch 4420/10000 training loss: 0.367854\n",
      "Batch 4430/10000 training loss: 0.273635\n",
      "Batch 4440/10000 training loss: 0.216890\n",
      "Batch 4450/10000 training loss: 0.337375\n",
      "Batch 4460/10000 training loss: 0.311813\n",
      "Batch 4470/10000 training loss: 0.365953\n",
      "Batch 4480/10000 training loss: 0.412985\n",
      "Batch 4490/10000 training loss: 0.367205\n",
      "Batch 4500/10000 training loss: 0.283309\n",
      "Batch 4510/10000 training loss: 0.427770\n",
      "Batch 4520/10000 training loss: 0.366351\n",
      "Batch 4530/10000 training loss: 0.372472\n",
      "Batch 4540/10000 training loss: 0.377554\n",
      "Batch 4550/10000 training loss: 0.320566\n",
      "Batch 4560/10000 training loss: 0.274998\n",
      "Batch 4570/10000 training loss: 0.397022\n",
      "Batch 4580/10000 training loss: 0.276309\n",
      "Batch 4590/10000 training loss: 0.500511\n",
      "Batch 4600/10000 training loss: 0.235121\n",
      "Batch 4610/10000 training loss: 0.289909\n",
      "Batch 4620/10000 training loss: 0.291687\n",
      "Batch 4630/10000 training loss: 0.317143\n",
      "Batch 4640/10000 training loss: 0.291247\n",
      "Batch 4650/10000 training loss: 0.232628\n",
      "Batch 4660/10000 training loss: 0.301136\n",
      "Batch 4670/10000 training loss: 0.396485\n",
      "Batch 4680/10000 training loss: 0.282550\n",
      "Batch 4690/10000 training loss: 0.242878\n",
      "Batch 4700/10000 training loss: 0.540755\n",
      "Batch 4710/10000 training loss: 0.439019\n",
      "Batch 4720/10000 training loss: 0.243433\n",
      "Batch 4730/10000 training loss: 0.285811\n",
      "Batch 4740/10000 training loss: 0.324303\n",
      "Batch 4750/10000 training loss: 0.285645\n",
      "Batch 4760/10000 training loss: 0.406956\n",
      "Batch 4770/10000 training loss: 0.319378\n",
      "Batch 4780/10000 training loss: 0.296066\n",
      "Batch 4790/10000 training loss: 0.237763\n",
      "Batch 4800/10000 training loss: 0.398966\n",
      "Batch 4810/10000 training loss: 0.176763\n",
      "Batch 4820/10000 training loss: 0.570365\n",
      "Batch 4830/10000 training loss: 0.179526\n",
      "Batch 4840/10000 training loss: 0.323858\n",
      "Batch 4850/10000 training loss: 0.218791\n",
      "Batch 4860/10000 training loss: 0.322642\n",
      "Batch 4870/10000 training loss: 0.216524\n",
      "Batch 4880/10000 training loss: 0.207596\n",
      "Batch 4890/10000 training loss: 0.253644\n",
      "Batch 4900/10000 training loss: 0.310572\n",
      "Batch 4910/10000 training loss: 0.417777\n",
      "Batch 4920/10000 training loss: 0.317711\n",
      "Batch 4930/10000 training loss: 0.450387\n",
      "Batch 4940/10000 training loss: 0.251786\n",
      "Batch 4950/10000 training loss: 0.165395\n",
      "Batch 4960/10000 training loss: 0.323273\n",
      "Batch 4970/10000 training loss: 0.244582\n",
      "Batch 4980/10000 training loss: 0.313149\n",
      "Batch 4990/10000 training loss: 0.336063\n",
      "Batch 5000/10000 training loss: 0.505762\n",
      "Batch 5010/10000 training loss: 0.555541\n",
      "Batch 5020/10000 training loss: 0.454485\n",
      "Batch 5030/10000 training loss: 0.287366\n",
      "Batch 5040/10000 training loss: 0.215153\n",
      "Batch 5050/10000 training loss: 0.277680\n",
      "Batch 5060/10000 training loss: 0.258807\n",
      "Batch 5070/10000 training loss: 0.403157\n",
      "Batch 5080/10000 training loss: 0.345431\n",
      "Batch 5090/10000 training loss: 0.171509\n",
      "Batch 5100/10000 training loss: 0.219583\n",
      "Batch 5110/10000 training loss: 0.458641\n",
      "Batch 5120/10000 training loss: 0.259358\n",
      "Batch 5130/10000 training loss: 0.524884\n",
      "Batch 5140/10000 training loss: 0.301941\n",
      "Batch 5150/10000 training loss: 0.313328\n",
      "Batch 5160/10000 training loss: 0.149525\n",
      "Batch 5170/10000 training loss: 0.272608\n",
      "Batch 5180/10000 training loss: 0.321269\n",
      "Batch 5190/10000 training loss: 0.358399\n",
      "Batch 5200/10000 training loss: 0.385302\n",
      "Batch 5210/10000 training loss: 0.236750\n",
      "Batch 5220/10000 training loss: 0.301978\n",
      "Batch 5230/10000 training loss: 0.225672\n",
      "Batch 5240/10000 training loss: 0.307704\n",
      "Batch 5250/10000 training loss: 0.286680\n",
      "Batch 5260/10000 training loss: 0.301739\n",
      "Batch 5270/10000 training loss: 0.291350\n",
      "Batch 5280/10000 training loss: 0.322644\n",
      "Batch 5290/10000 training loss: 0.274380\n",
      "Batch 5300/10000 training loss: 0.285866\n",
      "Batch 5310/10000 training loss: 0.241777\n",
      "Batch 5320/10000 training loss: 0.278229\n",
      "Batch 5330/10000 training loss: 0.229709\n",
      "Batch 5340/10000 training loss: 0.290814\n",
      "Batch 5350/10000 training loss: 0.196203\n",
      "Batch 5360/10000 training loss: 0.389900\n",
      "Batch 5370/10000 training loss: 0.332537\n",
      "Batch 5380/10000 training loss: 0.244960\n",
      "Batch 5390/10000 training loss: 0.260280\n",
      "Batch 5400/10000 training loss: 0.283470\n",
      "Batch 5410/10000 training loss: 0.221235\n",
      "Batch 5420/10000 training loss: 0.277968\n",
      "Batch 5430/10000 training loss: 0.226118\n",
      "Batch 5440/10000 training loss: 0.382690\n",
      "Batch 5450/10000 training loss: 0.344084\n",
      "Batch 5460/10000 training loss: 0.161512\n",
      "Batch 5470/10000 training loss: 0.407204\n",
      "Batch 5480/10000 training loss: 0.260301\n",
      "Batch 5490/10000 training loss: 0.254827\n",
      "Batch 5500/10000 training loss: 0.210717\n",
      "Batch 5510/10000 training loss: 0.358791\n",
      "Batch 5520/10000 training loss: 0.475767\n",
      "Batch 5530/10000 training loss: 0.299012\n",
      "Batch 5540/10000 training loss: 0.276732\n",
      "Batch 5550/10000 training loss: 0.238699\n",
      "Batch 5560/10000 training loss: 0.427904\n",
      "Batch 5570/10000 training loss: 0.274758\n",
      "Batch 5580/10000 training loss: 0.333645\n",
      "Batch 5590/10000 training loss: 0.360942\n",
      "Batch 5600/10000 training loss: 0.265843\n",
      "Batch 5610/10000 training loss: 0.296196\n",
      "Batch 5620/10000 training loss: 0.229740\n",
      "Batch 5630/10000 training loss: 0.220621\n",
      "Batch 5640/10000 training loss: 0.393523\n",
      "Batch 5650/10000 training loss: 0.268106\n",
      "Batch 5660/10000 training loss: 0.382902\n",
      "Batch 5670/10000 training loss: 0.385854\n",
      "Batch 5680/10000 training loss: 0.275248\n",
      "Batch 5690/10000 training loss: 0.401878\n",
      "Batch 5700/10000 training loss: 0.238054\n",
      "Batch 5710/10000 training loss: 0.327982\n",
      "Batch 5720/10000 training loss: 0.324344\n",
      "Batch 5730/10000 training loss: 0.169387\n",
      "Batch 5740/10000 training loss: 0.243799\n",
      "Batch 5750/10000 training loss: 0.392256\n",
      "Batch 5760/10000 training loss: 0.364842\n",
      "Batch 5770/10000 training loss: 0.225031\n",
      "Batch 5780/10000 training loss: 0.287166\n",
      "Batch 5790/10000 training loss: 0.364815\n",
      "Batch 5800/10000 training loss: 0.574316\n",
      "Batch 5810/10000 training loss: 0.304625\n",
      "Batch 5820/10000 training loss: 0.294573\n",
      "Batch 5830/10000 training loss: 0.493588\n",
      "Batch 5840/10000 training loss: 0.349237\n",
      "Batch 5850/10000 training loss: 0.322488\n",
      "Batch 5860/10000 training loss: 0.417351\n",
      "Batch 5870/10000 training loss: 0.381373\n",
      "Batch 5880/10000 training loss: 0.409418\n",
      "Batch 5890/10000 training loss: 0.365161\n",
      "Batch 5900/10000 training loss: 0.297333\n",
      "Batch 5910/10000 training loss: 0.249070\n",
      "Batch 5920/10000 training loss: 0.244742\n",
      "Batch 5930/10000 training loss: 0.168155\n",
      "Batch 5940/10000 training loss: 0.261959\n",
      "Batch 5950/10000 training loss: 0.320285\n",
      "Batch 5960/10000 training loss: 0.369568\n",
      "Batch 5970/10000 training loss: 0.325759\n",
      "Batch 5980/10000 training loss: 0.251693\n",
      "Batch 5990/10000 training loss: 0.291270\n",
      "Batch 6000/10000 training loss: 0.243272\n",
      "Batch 6010/10000 training loss: 0.218548\n",
      "Batch 6020/10000 training loss: 0.177721\n",
      "Batch 6030/10000 training loss: 0.388730\n",
      "Batch 6040/10000 training loss: 0.276426\n",
      "Batch 6050/10000 training loss: 0.388808\n",
      "Batch 6060/10000 training loss: 0.281755\n",
      "Batch 6070/10000 training loss: 0.210057\n",
      "Batch 6080/10000 training loss: 0.340365\n",
      "Batch 6090/10000 training loss: 0.563227\n",
      "Batch 6100/10000 training loss: 0.222265\n",
      "Batch 6110/10000 training loss: 0.370833\n",
      "Batch 6120/10000 training loss: 0.257924\n",
      "Batch 6130/10000 training loss: 0.237501\n",
      "Batch 6140/10000 training loss: 0.191587\n",
      "Batch 6150/10000 training loss: 0.217226\n",
      "Batch 6160/10000 training loss: 0.375622\n",
      "Batch 6170/10000 training loss: 0.495237\n",
      "Batch 6180/10000 training loss: 0.321117\n",
      "Batch 6190/10000 training loss: 0.359016\n",
      "Batch 6200/10000 training loss: 0.380779\n",
      "Batch 6210/10000 training loss: 0.341791\n",
      "Batch 6220/10000 training loss: 0.376185\n",
      "Batch 6230/10000 training loss: 0.337884\n",
      "Batch 6240/10000 training loss: 0.457266\n",
      "Batch 6250/10000 training loss: 0.312377\n",
      "Batch 6260/10000 training loss: 0.281815\n",
      "Batch 6270/10000 training loss: 0.199160\n",
      "Batch 6280/10000 training loss: 0.334001\n",
      "Batch 6290/10000 training loss: 0.330404\n",
      "Batch 6300/10000 training loss: 0.389342\n",
      "Batch 6310/10000 training loss: 0.310751\n",
      "Batch 6320/10000 training loss: 0.171517\n",
      "Batch 6330/10000 training loss: 0.360233\n",
      "Batch 6340/10000 training loss: 0.173352\n",
      "Batch 6350/10000 training loss: 0.215191\n",
      "Batch 6360/10000 training loss: 0.210662\n",
      "Batch 6370/10000 training loss: 0.428613\n",
      "Batch 6380/10000 training loss: 0.317773\n",
      "Batch 6390/10000 training loss: 0.222486\n",
      "Batch 6400/10000 training loss: 0.397853\n",
      "Batch 6410/10000 training loss: 0.232747\n",
      "Batch 6420/10000 training loss: 0.176438\n",
      "Batch 6430/10000 training loss: 0.461049\n",
      "Batch 6440/10000 training loss: 0.413295\n",
      "Batch 6450/10000 training loss: 0.161421\n",
      "Batch 6460/10000 training loss: 0.335096\n",
      "Batch 6470/10000 training loss: 0.309457\n",
      "Batch 6480/10000 training loss: 0.218498\n",
      "Batch 6490/10000 training loss: 0.171512\n",
      "Batch 6500/10000 training loss: 0.202960\n",
      "Batch 6510/10000 training loss: 0.288487\n",
      "Batch 6520/10000 training loss: 0.256691\n",
      "Batch 6530/10000 training loss: 0.443617\n",
      "Batch 6540/10000 training loss: 0.186449\n",
      "Batch 6550/10000 training loss: 0.214597\n",
      "Batch 6560/10000 training loss: 0.251736\n",
      "Batch 6570/10000 training loss: 0.233084\n",
      "Batch 6580/10000 training loss: 0.268658\n",
      "Batch 6590/10000 training loss: 0.448806\n",
      "Batch 6600/10000 training loss: 0.254304\n",
      "Batch 6610/10000 training loss: 0.214804\n",
      "Batch 6620/10000 training loss: 0.435660\n",
      "Batch 6630/10000 training loss: 0.398646\n",
      "Batch 6640/10000 training loss: 0.410729\n",
      "Batch 6650/10000 training loss: 0.304833\n",
      "Batch 6660/10000 training loss: 0.330944\n",
      "Batch 6670/10000 training loss: 0.317609\n",
      "Batch 6680/10000 training loss: 0.285153\n",
      "Batch 6690/10000 training loss: 0.340068\n",
      "Batch 6700/10000 training loss: 0.264344\n",
      "Batch 6710/10000 training loss: 0.238809\n",
      "Batch 6720/10000 training loss: 0.434602\n",
      "Batch 6730/10000 training loss: 0.299861\n",
      "Batch 6740/10000 training loss: 0.326206\n",
      "Batch 6750/10000 training loss: 0.210964\n",
      "Batch 6760/10000 training loss: 0.434785\n",
      "Batch 6770/10000 training loss: 0.224952\n",
      "Batch 6780/10000 training loss: 0.359689\n",
      "Batch 6790/10000 training loss: 0.351086\n",
      "Batch 6800/10000 training loss: 0.302050\n",
      "Batch 6810/10000 training loss: 0.229903\n",
      "Batch 6820/10000 training loss: 0.223750\n",
      "Batch 6830/10000 training loss: 0.343567\n",
      "Batch 6840/10000 training loss: 0.310169\n",
      "Batch 6850/10000 training loss: 0.356326\n",
      "Batch 6860/10000 training loss: 0.394245\n",
      "Batch 6870/10000 training loss: 0.223603\n",
      "Batch 6880/10000 training loss: 0.465112\n",
      "Batch 6890/10000 training loss: 0.307880\n",
      "Batch 6900/10000 training loss: 0.345416\n",
      "Batch 6910/10000 training loss: 0.324162\n",
      "Batch 6920/10000 training loss: 0.337213\n",
      "Batch 6930/10000 training loss: 0.196370\n",
      "Batch 6940/10000 training loss: 0.395894\n",
      "Batch 6950/10000 training loss: 0.194516\n",
      "Batch 6960/10000 training loss: 0.253350\n",
      "Batch 6970/10000 training loss: 0.292278\n",
      "Batch 6980/10000 training loss: 0.358557\n",
      "Batch 6990/10000 training loss: 0.261985\n",
      "Batch 7000/10000 training loss: 0.196540\n",
      "Batch 7010/10000 training loss: 0.214489\n",
      "Batch 7020/10000 training loss: 0.283495\n",
      "Batch 7030/10000 training loss: 0.325132\n",
      "Batch 7040/10000 training loss: 0.270777\n",
      "Batch 7050/10000 training loss: 0.295374\n",
      "Batch 7060/10000 training loss: 0.476162\n",
      "Batch 7070/10000 training loss: 0.258947\n",
      "Batch 7080/10000 training loss: 0.371839\n",
      "Batch 7090/10000 training loss: 0.437989\n",
      "Batch 7100/10000 training loss: 0.189934\n",
      "Batch 7110/10000 training loss: 0.204323\n",
      "Batch 7120/10000 training loss: 0.438529\n",
      "Batch 7130/10000 training loss: 0.198946\n",
      "Batch 7140/10000 training loss: 0.338971\n",
      "Batch 7150/10000 training loss: 0.379760\n",
      "Batch 7160/10000 training loss: 0.211028\n",
      "Batch 7170/10000 training loss: 0.326590\n",
      "Batch 7180/10000 training loss: 0.412816\n",
      "Batch 7190/10000 training loss: 0.239643\n",
      "Batch 7200/10000 training loss: 0.382765\n",
      "Batch 7210/10000 training loss: 0.286725\n",
      "Batch 7220/10000 training loss: 0.293782\n",
      "Batch 7230/10000 training loss: 0.269237\n",
      "Batch 7240/10000 training loss: 0.504445\n",
      "Batch 7250/10000 training loss: 0.201026\n",
      "Batch 7260/10000 training loss: 0.352406\n",
      "Batch 7270/10000 training loss: 0.367343\n",
      "Batch 7280/10000 training loss: 0.199750\n",
      "Batch 7290/10000 training loss: 0.397885\n",
      "Batch 7300/10000 training loss: 0.359779\n",
      "Batch 7310/10000 training loss: 0.250591\n",
      "Batch 7320/10000 training loss: 0.482439\n",
      "Batch 7330/10000 training loss: 0.203084\n",
      "Batch 7340/10000 training loss: 0.274710\n",
      "Batch 7350/10000 training loss: 0.296841\n",
      "Batch 7360/10000 training loss: 0.431703\n",
      "Batch 7370/10000 training loss: 0.226339\n",
      "Batch 7380/10000 training loss: 0.345600\n",
      "Batch 7390/10000 training loss: 0.430338\n",
      "Batch 7400/10000 training loss: 0.340173\n",
      "Batch 7410/10000 training loss: 0.293436\n",
      "Batch 7420/10000 training loss: 0.426188\n",
      "Batch 7430/10000 training loss: 0.440575\n",
      "Batch 7440/10000 training loss: 0.441745\n",
      "Batch 7450/10000 training loss: 0.250774\n",
      "Batch 7460/10000 training loss: 0.153218\n",
      "Batch 7470/10000 training loss: 0.249418\n",
      "Batch 7480/10000 training loss: 0.419160\n",
      "Batch 7490/10000 training loss: 0.354568\n",
      "Batch 7500/10000 training loss: 0.179843\n",
      "Batch 7510/10000 training loss: 0.233006\n",
      "Batch 7520/10000 training loss: 0.204049\n",
      "Batch 7530/10000 training loss: 0.220075\n",
      "Batch 7540/10000 training loss: 0.381853\n",
      "Batch 7550/10000 training loss: 0.296217\n",
      "Batch 7560/10000 training loss: 0.165949\n",
      "Batch 7570/10000 training loss: 0.245536\n",
      "Batch 7580/10000 training loss: 0.296773\n",
      "Batch 7590/10000 training loss: 0.336766\n",
      "Batch 7600/10000 training loss: 0.371092\n",
      "Batch 7610/10000 training loss: 0.278848\n",
      "Batch 7620/10000 training loss: 0.219849\n",
      "Batch 7630/10000 training loss: 0.286685\n",
      "Batch 7640/10000 training loss: 0.376361\n",
      "Batch 7650/10000 training loss: 0.208931\n",
      "Batch 7660/10000 training loss: 0.196324\n",
      "Batch 7670/10000 training loss: 0.273441\n",
      "Batch 7680/10000 training loss: 0.415531\n",
      "Batch 7690/10000 training loss: 0.205891\n",
      "Batch 7700/10000 training loss: 0.308499\n",
      "Batch 7710/10000 training loss: 0.422528\n",
      "Batch 7720/10000 training loss: 0.401349\n",
      "Batch 7730/10000 training loss: 0.392824\n",
      "Batch 7740/10000 training loss: 0.414799\n",
      "Batch 7750/10000 training loss: 0.188631\n",
      "Batch 7760/10000 training loss: 0.276261\n",
      "Batch 7770/10000 training loss: 0.226876\n",
      "Batch 7780/10000 training loss: 0.297827\n",
      "Batch 7790/10000 training loss: 0.260738\n",
      "Batch 7800/10000 training loss: 0.226605\n",
      "Batch 7810/10000 training loss: 0.530303\n",
      "Batch 7820/10000 training loss: 0.331458\n",
      "Batch 7830/10000 training loss: 0.238182\n",
      "Batch 7840/10000 training loss: 0.332446\n",
      "Batch 7850/10000 training loss: 0.341370\n",
      "Batch 7860/10000 training loss: 0.336164\n",
      "Batch 7870/10000 training loss: 0.445559\n",
      "Batch 7880/10000 training loss: 0.375425\n",
      "Batch 7890/10000 training loss: 0.278056\n",
      "Batch 7900/10000 training loss: 0.200491\n",
      "Batch 7910/10000 training loss: 0.223850\n",
      "Batch 7920/10000 training loss: 0.246762\n",
      "Batch 7930/10000 training loss: 0.179172\n",
      "Batch 7940/10000 training loss: 0.329251\n",
      "Batch 7950/10000 training loss: 0.338243\n",
      "Batch 7960/10000 training loss: 0.382050\n",
      "Batch 7970/10000 training loss: 0.305705\n",
      "Batch 7980/10000 training loss: 0.351516\n",
      "Batch 7990/10000 training loss: 0.294406\n",
      "Batch 8000/10000 training loss: 0.259206\n",
      "Batch 8010/10000 training loss: 0.241977\n",
      "Batch 8020/10000 training loss: 0.314256\n",
      "Batch 8030/10000 training loss: 0.217167\n",
      "Batch 8040/10000 training loss: 0.246964\n",
      "Batch 8050/10000 training loss: 0.286118\n",
      "Batch 8060/10000 training loss: 0.176612\n",
      "Batch 8070/10000 training loss: 0.285004\n",
      "Batch 8080/10000 training loss: 0.160391\n",
      "Batch 8090/10000 training loss: 0.284074\n",
      "Batch 8100/10000 training loss: 0.248948\n",
      "Batch 8110/10000 training loss: 0.194195\n",
      "Batch 8120/10000 training loss: 0.200972\n",
      "Batch 8130/10000 training loss: 0.370406\n",
      "Batch 8140/10000 training loss: 0.305758\n",
      "Batch 8150/10000 training loss: 0.578740\n",
      "Batch 8160/10000 training loss: 0.383540\n",
      "Batch 8170/10000 training loss: 0.340755\n",
      "Batch 8180/10000 training loss: 0.297647\n",
      "Batch 8190/10000 training loss: 0.381810\n",
      "Batch 8200/10000 training loss: 0.272508\n",
      "Batch 8210/10000 training loss: 0.336890\n",
      "Batch 8220/10000 training loss: 0.264277\n",
      "Batch 8230/10000 training loss: 0.183959\n",
      "Batch 8240/10000 training loss: 0.227343\n",
      "Batch 8250/10000 training loss: 0.326238\n",
      "Batch 8260/10000 training loss: 0.282948\n",
      "Batch 8270/10000 training loss: 0.264025\n",
      "Batch 8280/10000 training loss: 0.238383\n",
      "Batch 8290/10000 training loss: 0.498885\n",
      "Batch 8300/10000 training loss: 0.232156\n",
      "Batch 8310/10000 training loss: 0.299465\n",
      "Batch 8320/10000 training loss: 0.217765\n",
      "Batch 8330/10000 training loss: 0.284308\n",
      "Batch 8340/10000 training loss: 0.444913\n",
      "Batch 8350/10000 training loss: 0.275310\n",
      "Batch 8360/10000 training loss: 0.223223\n",
      "Batch 8370/10000 training loss: 0.188627\n",
      "Batch 8380/10000 training loss: 0.225866\n",
      "Batch 8390/10000 training loss: 0.365705\n",
      "Batch 8400/10000 training loss: 0.238566\n",
      "Batch 8410/10000 training loss: 0.307523\n",
      "Batch 8420/10000 training loss: 0.226968\n",
      "Batch 8430/10000 training loss: 0.251981\n",
      "Batch 8440/10000 training loss: 0.502168\n",
      "Batch 8450/10000 training loss: 0.291226\n",
      "Batch 8460/10000 training loss: 0.307007\n",
      "Batch 8470/10000 training loss: 0.281932\n",
      "Batch 8480/10000 training loss: 0.299037\n",
      "Batch 8490/10000 training loss: 0.126073\n",
      "Batch 8500/10000 training loss: 0.390136\n",
      "Batch 8510/10000 training loss: 0.262458\n",
      "Batch 8520/10000 training loss: 0.257225\n",
      "Batch 8530/10000 training loss: 0.228102\n",
      "Batch 8540/10000 training loss: 0.403145\n",
      "Batch 8550/10000 training loss: 0.385529\n",
      "Batch 8560/10000 training loss: 0.183458\n",
      "Batch 8570/10000 training loss: 0.186385\n",
      "Batch 8580/10000 training loss: 0.222203\n",
      "Batch 8590/10000 training loss: 0.474349\n",
      "Batch 8600/10000 training loss: 0.321048\n",
      "Batch 8610/10000 training loss: 0.273443\n",
      "Batch 8620/10000 training loss: 0.352430\n",
      "Batch 8630/10000 training loss: 0.202967\n",
      "Batch 8640/10000 training loss: 0.254514\n",
      "Batch 8650/10000 training loss: 0.578848\n",
      "Batch 8660/10000 training loss: 0.244305\n",
      "Batch 8670/10000 training loss: 0.381004\n",
      "Batch 8680/10000 training loss: 0.282268\n",
      "Batch 8690/10000 training loss: 0.410661\n",
      "Batch 8700/10000 training loss: 0.433336\n",
      "Batch 8710/10000 training loss: 0.391237\n",
      "Batch 8720/10000 training loss: 0.208583\n",
      "Batch 8730/10000 training loss: 0.224615\n",
      "Batch 8740/10000 training loss: 0.196997\n",
      "Batch 8750/10000 training loss: 0.222889\n",
      "Batch 8760/10000 training loss: 0.297828\n",
      "Batch 8770/10000 training loss: 0.219338\n",
      "Batch 8780/10000 training loss: 0.297065\n",
      "Batch 8790/10000 training loss: 0.405282\n",
      "Batch 8800/10000 training loss: 0.302697\n",
      "Batch 8810/10000 training loss: 0.318718\n",
      "Batch 8820/10000 training loss: 0.282687\n",
      "Batch 8830/10000 training loss: 0.296376\n",
      "Batch 8840/10000 training loss: 0.211594\n",
      "Batch 8850/10000 training loss: 0.242767\n",
      "Batch 8860/10000 training loss: 0.387514\n",
      "Batch 8870/10000 training loss: 0.378652\n",
      "Batch 8880/10000 training loss: 0.314196\n",
      "Batch 8890/10000 training loss: 0.196111\n",
      "Batch 8900/10000 training loss: 0.334983\n",
      "Batch 8910/10000 training loss: 0.186419\n",
      "Batch 8920/10000 training loss: 0.171856\n",
      "Batch 8930/10000 training loss: 0.187079\n",
      "Batch 8940/10000 training loss: 0.183230\n",
      "Batch 8950/10000 training loss: 0.303278\n",
      "Batch 8960/10000 training loss: 0.271348\n",
      "Batch 8970/10000 training loss: 0.331227\n",
      "Batch 8980/10000 training loss: 0.217291\n",
      "Batch 8990/10000 training loss: 0.374789\n",
      "Batch 9000/10000 training loss: 0.183499\n",
      "Batch 9010/10000 training loss: 0.399265\n",
      "Batch 9020/10000 training loss: 0.175803\n",
      "Batch 9030/10000 training loss: 0.234439\n",
      "Batch 9040/10000 training loss: 0.291267\n",
      "Batch 9050/10000 training loss: 0.171320\n",
      "Batch 9060/10000 training loss: 0.198398\n",
      "Batch 9070/10000 training loss: 0.185066\n",
      "Batch 9080/10000 training loss: 0.287752\n",
      "Batch 9090/10000 training loss: 0.204395\n",
      "Batch 9100/10000 training loss: 0.233574\n",
      "Batch 9110/10000 training loss: 0.227770\n",
      "Batch 9120/10000 training loss: 0.173702\n",
      "Batch 9130/10000 training loss: 0.219869\n",
      "Batch 9140/10000 training loss: 0.299334\n",
      "Batch 9150/10000 training loss: 0.470754\n",
      "Batch 9160/10000 training loss: 0.437426\n",
      "Batch 9170/10000 training loss: 0.339074\n",
      "Batch 9180/10000 training loss: 0.353490\n",
      "Batch 9190/10000 training loss: 0.317874\n",
      "Batch 9200/10000 training loss: 0.355957\n",
      "Batch 9210/10000 training loss: 0.235545\n",
      "Batch 9220/10000 training loss: 0.199810\n",
      "Batch 9230/10000 training loss: 0.216991\n",
      "Batch 9240/10000 training loss: 0.235440\n",
      "Batch 9250/10000 training loss: 0.328639\n",
      "Batch 9260/10000 training loss: 0.191619\n",
      "Batch 9270/10000 training loss: 0.411104\n",
      "Batch 9280/10000 training loss: 0.284950\n",
      "Batch 9290/10000 training loss: 0.268769\n",
      "Batch 9300/10000 training loss: 0.356287\n",
      "Batch 9310/10000 training loss: 0.308316\n",
      "Batch 9320/10000 training loss: 0.452079\n",
      "Batch 9330/10000 training loss: 0.284328\n",
      "Batch 9340/10000 training loss: 0.336844\n",
      "Batch 9350/10000 training loss: 0.221004\n",
      "Batch 9360/10000 training loss: 0.366877\n",
      "Batch 9370/10000 training loss: 0.205307\n",
      "Batch 9380/10000 training loss: 0.319596\n",
      "Batch 9390/10000 training loss: 0.179612\n",
      "Batch 9400/10000 training loss: 0.165439\n",
      "Batch 9410/10000 training loss: 0.241321\n",
      "Batch 9420/10000 training loss: 0.446503\n",
      "Batch 9430/10000 training loss: 0.304494\n",
      "Batch 9440/10000 training loss: 0.388867\n",
      "Batch 9450/10000 training loss: 0.267302\n",
      "Batch 9460/10000 training loss: 0.146959\n",
      "Batch 9470/10000 training loss: 0.219015\n",
      "Batch 9480/10000 training loss: 0.406147\n",
      "Batch 9490/10000 training loss: 0.293297\n",
      "Batch 9500/10000 training loss: 0.295889\n",
      "Batch 9510/10000 training loss: 0.310017\n",
      "Batch 9520/10000 training loss: 0.291713\n",
      "Batch 9530/10000 training loss: 0.235215\n",
      "Batch 9540/10000 training loss: 0.456247\n",
      "Batch 9550/10000 training loss: 0.446436\n",
      "Batch 9560/10000 training loss: 0.289575\n",
      "Batch 9570/10000 training loss: 0.289717\n",
      "Batch 9580/10000 training loss: 0.404880\n",
      "Batch 9590/10000 training loss: 0.301864\n",
      "Batch 9600/10000 training loss: 0.221910\n",
      "Batch 9610/10000 training loss: 0.239407\n",
      "Batch 9620/10000 training loss: 0.210950\n",
      "Batch 9630/10000 training loss: 0.246080\n",
      "Batch 9640/10000 training loss: 0.331580\n",
      "Batch 9650/10000 training loss: 0.354528\n",
      "Batch 9660/10000 training loss: 0.286484\n",
      "Batch 9670/10000 training loss: 0.258108\n",
      "Batch 9680/10000 training loss: 0.182839\n",
      "Batch 9690/10000 training loss: 0.193501\n",
      "Batch 9700/10000 training loss: 0.390800\n",
      "Batch 9710/10000 training loss: 0.346798\n",
      "Batch 9720/10000 training loss: 0.357149\n",
      "Batch 9730/10000 training loss: 0.215305\n",
      "Batch 9740/10000 training loss: 0.293470\n",
      "Batch 9750/10000 training loss: 0.244513\n",
      "Batch 9760/10000 training loss: 0.224392\n",
      "Batch 9770/10000 training loss: 0.276430\n",
      "Batch 9780/10000 training loss: 0.195250\n",
      "Batch 9790/10000 training loss: 0.307022\n",
      "Batch 9800/10000 training loss: 0.280307\n",
      "Batch 9810/10000 training loss: 0.150547\n",
      "Batch 9820/10000 training loss: 0.324454\n",
      "Batch 9830/10000 training loss: 0.253777\n",
      "Batch 9840/10000 training loss: 0.185297\n",
      "Batch 9850/10000 training loss: 0.277798\n",
      "Batch 9860/10000 training loss: 0.118447\n",
      "Batch 9870/10000 training loss: 0.382048\n",
      "Batch 9880/10000 training loss: 0.406977\n",
      "Batch 9890/10000 training loss: 0.247352\n",
      "Batch 9900/10000 training loss: 0.246674\n",
      "Batch 9910/10000 training loss: 0.241541\n",
      "Batch 9920/10000 training loss: 0.215355\n",
      "Batch 9930/10000 training loss: 0.315167\n",
      "Batch 9940/10000 training loss: 0.286768\n",
      "Batch 9950/10000 training loss: 0.432367\n",
      "Batch 9960/10000 training loss: 0.224874\n",
      "Batch 9970/10000 training loss: 0.133159\n",
      "Batch 9980/10000 training loss: 0.528665\n",
      "Batch 9990/10000 training loss: 0.232412\n",
      "Batch 10000/10000 training loss: 0.250218\n",
      "Total time training 20 epochs: 12.769733002991416 s\n"
     ]
    }
   ],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# specify number of epochs to run through whole dataset\n",
    "num_epochs = 20 # approx xxx s / epoch on laptop (macbook pro 13\" i7 end 2011 w/ 8GB RAM) w/ batch_size = 100\n",
    "# compute total amount of batches to be run\n",
    "train_size = 50000\n",
    "# specify batch_size \n",
    "batch_size = 100\n",
    "num_batches = int((train_size / batch_size) * num_epochs)\n",
    "# print loss after this amount of batches\n",
    "print_every = 10\n",
    "\n",
    "tr_losses = []\n",
    "print('Training...')\n",
    "beg_t = timeit.default_timer()\n",
    "# Run the training iterations\n",
    "for curr_batch in range(num_batches):\n",
    "    # get the batches of training images (injected to x placeholder) and labels (injected to y_ placeholder)\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    # run model update (learning stage over a batch of samples)\n",
    "    tr_loss , _= sess.run([loss, train_step], feed_dict={x: batch_x, y_:batch_y})\n",
    "    tr_losses.append(tr_loss)\n",
    "    if (curr_batch + 1) % print_every == 0:\n",
    "        print('Batch {}/{} training loss: {:.6f}'.format(curr_batch + 1, num_batches, tr_loss))\n",
    "end_t = timeit.default_timer()\n",
    "print('Total time training {} epochs: {} s'.format(num_epochs, end_t - beg_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x124adbb00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAEKCAYAAAAYW4wpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124838978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.semilogy(tr_losses)\n",
    "plt.xlabel('Batch index')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in classifying mnist digits: 0.9208999872207642\n"
     ]
    }
   ],
   "source": [
    "# Test trained model\n",
    "# cache the real test images and labels\n",
    "te_x_batch = mnist.test.images\n",
    "te_y_batch = mnist.test.labels\n",
    "# define the accuracy computation op\n",
    "# NOTE: must take the argmax of prediction at softmax output to get predicted class with more probability\n",
    "# Argmax also done in y_ to get index out of one-hot vector\n",
    "correct_prediction = tf.equal(tf.argmax(out,dimension=1), tf.argmax(y_,dimension=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy in classifying '\n",
    "      'mnist digits: {}'.format(sess.run(accuracy, feed_dict={x:te_x_batch, y_:te_y_batch})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
